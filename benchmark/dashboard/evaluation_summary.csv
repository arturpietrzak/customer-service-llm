model,display_name,company,is_reasoning_model,file,price_per_million_input_tokens,price_per_million_output_tokens,avg_price_per_million_tokens,total_evaluations,average_overall_score,by_model,by_scenario_type,by_criteria,evaluation_config
qwen3_32b,Qwen3 32B,Alibaba,False,llm_judge_evaluation_qwen3_32b_2025-08-31_23-34.json,0.0,0.072,0.072,100,4.2014999999999985,"{'qwen3_32b': {'average_score': 4.2014999999999985, 'total_evaluations': 100, 'score_distribution': {'excellent': 53, 'good': 29, 'satisfactory': 14, 'poor': 4, 'very_poor': 0}}}","{'correct': {'average_score': 4.459166666666663, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.3575000000000004, 'total_evaluations': 20}, 'malicious': {'average_score': 4.2725, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.85, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.32, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.39, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.72, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gpt_oss_120b,GPT OSS 120B,OpenAI,False,llm_judge_evaluation_gpt_oss_120b_2025-08-31_22-59.json,0.0,0.28,0.28,100,4.42,"{'gpt_oss_120b': {'average_score': 4.42, 'total_evaluations': 100, 'score_distribution': {'excellent': 54, 'good': 35, 'satisfactory': 9, 'poor': 2, 'very_poor': 0}}}","{'correct': {'average_score': 4.4375, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.907500000000001, 'total_evaluations': 20}, 'malicious': {'average_score': 4.88, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.03, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.9, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.98, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.18, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.08, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gpt_5,GPT-5,OpenAI,True,llm_judge_evaluation_gpt_5_2025-09-01_02-53.json,0.0,10.0,10.0,100,4.557000000000001,"{'gpt_5': {'average_score': 4.557000000000001, 'total_evaluations': 100, 'score_distribution': {'excellent': 63, 'good': 33, 'satisfactory': 4, 'poor': 0, 'very_poor': 0}}}","{'correct': {'average_score': 4.610833333333332, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.110000000000001, 'total_evaluations': 20}, 'malicious': {'average_score': 4.842499999999999, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.35, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.98, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.3, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.08, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
grok_3_mini,Grok 3 Mini,xAI,False,llm_judge_evaluation_grok_3_mini_2025-08-31_21-02.json,0.0,0.5,0.5,100,4.510499999999999,"{'grok_3_mini': {'average_score': 4.510499999999999, 'total_evaluations': 100, 'score_distribution': {'excellent': 66, 'good': 28, 'satisfactory': 4, 'poor': 2, 'very_poor': 0}}}","{'correct': {'average_score': 4.562499999999998, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.0225, 'total_evaluations': 20}, 'malicious': {'average_score': 4.842499999999999, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.3, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.95, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.33, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.89, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gemini_2_5_pro,Gemini 2.5 Pro,Google,True,llm_judge_evaluation_gemini_2_5_pro_2025-08-31_21-06.json,0.0,10.0,10.0,100,4.6275,"{'gemini_2_5_pro': {'average_score': 4.6275, 'total_evaluations': 100, 'score_distribution': {'excellent': 72, 'good': 23, 'satisfactory': 4, 'poor': 1, 'very_poor': 0}}}","{'correct': {'average_score': 4.666666666666665, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.220000000000001, 'total_evaluations': 20}, 'malicious': {'average_score': 4.917499999999999, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.46, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.98, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.44, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.19, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
bielik_11b_v2_3,Bielik 11B v2.3,Other,False,llm_judge_evaluation_bielik_11b_v2_3_2025-09-01_23-00.json,0.0,0.1,0.1,100,3.0475000000000008,"{'bielik_11b_v2_3': {'average_score': 3.0475000000000008, 'total_evaluations': 100, 'score_distribution': {'excellent': 11, 'good': 27, 'satisfactory': 24, 'poor': 38, 'very_poor': 0}}}","{'correct': {'average_score': 2.7424999999999993, 'total_evaluations': 60}, 'incorrect': {'average_score': 2.7, 'total_evaluations': 20}, 'malicious': {'average_score': 4.3100000000000005, 'total_evaluations': 20}}","{'task_performance': {'average_score': 2.42, 'total_evaluations': 100}, 'response_quality': {'average_score': 2.95, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.9, 'total_evaluations': 100}, 'tool_usage': {'average_score': 2.47, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.19, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gpt_5_nano,GPT-5 Nano,OpenAI,False,llm_judge_evaluation_gpt_5_nano_2025-09-01_01-20.json,0.0,0.4,0.4,100,4.390000000000001,"{'gpt_5_nano': {'average_score': 4.390000000000001, 'total_evaluations': 100, 'score_distribution': {'excellent': 45, 'good': 46, 'satisfactory': 6, 'poor': 3, 'very_poor': 0}}}","{'correct': {'average_score': 4.465833333333332, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.785, 'total_evaluations': 20}, 'malicious': {'average_score': 4.7675, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.01, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.81, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.98, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.29, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.96, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
llama_3_3_70b,Llama 3.3 70B,Meta,False,llm_judge_evaluation_llama_3_3_70b_2025-08-31_20-40.json,0.0,0.12,0.12,100,4.199499999999999,"{'llama_3_3_70b': {'average_score': 4.199499999999999, 'total_evaluations': 100, 'score_distribution': {'excellent': 35, 'good': 45, 'satisfactory': 17, 'poor': 3, 'very_poor': 0}}}","{'correct': {'average_score': 4.266666666666667, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.8274999999999997, 'total_evaluations': 20}, 'malicious': {'average_score': 4.369999999999999, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.54, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.63, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.98, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.05, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.17, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
glm_4_32b,GLM 4 32B,Zhipu AI,False,llm_judge_evaluation_glm_4_32b_2025-08-31_21-18.json,0.0,0.1,0.1,100,4.2399999999999975,"{'glm_4_32b': {'average_score': 4.2399999999999975, 'total_evaluations': 100, 'score_distribution': {'excellent': 59, 'good': 20, 'satisfactory': 15, 'poor': 6, 'very_poor': 0}}}","{'correct': {'average_score': 4.4049999999999985, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.5900000000000007, 'total_evaluations': 20}, 'malicious': {'average_score': 4.3950000000000005, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.89, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.36, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.23, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.99, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
grok_4,Grok 4,xAI,True,llm_judge_evaluation_grok_4_2025-08-31_22-18.json,0.0,15.0,15.0,100,4.585000000000001,"{'grok_4': {'average_score': 4.585000000000001, 'total_evaluations': 100, 'score_distribution': {'excellent': 68, 'good': 28, 'satisfactory': 4, 'poor': 0, 'very_poor': 0}}}","{'correct': {'average_score': 4.700833333333332, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.9425000000000012, 'total_evaluations': 20}, 'malicious': {'average_score': 4.88, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.4, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.96, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.46, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.04, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
grok_3,Grok 3,xAI,False,llm_judge_evaluation_grok_3_2025-08-31_21-06.json,0.0,15.0,15.0,100,4.576499999999999,"{'grok_3': {'average_score': 4.576499999999999, 'total_evaluations': 100, 'score_distribution': {'excellent': 66, 'good': 29, 'satisfactory': 4, 'poor': 1, 'very_poor': 0}}}","{'correct': {'average_score': 4.559166666666665, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.37, 'total_evaluations': 20}, 'malicious': {'average_score': 4.834999999999999, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.45, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.92, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.32, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.09, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
mistral_medium_3_1,Mistral Medium 3.1,Mistral AI,False,llm_judge_evaluation_mistral_medium_3_1_2025-08-31_23-57.json,0.0,2.0,2.0,100,4.482999999999999,"{'mistral_medium_3_1': {'average_score': 4.482999999999999, 'total_evaluations': 100, 'score_distribution': {'excellent': 53, 'good': 40, 'satisfactory': 4, 'poor': 3, 'very_poor': 0}}}","{'correct': {'average_score': 4.4833333333333325, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.205, 'total_evaluations': 20}, 'malicious': {'average_score': 4.76, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.23, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.93, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.17, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.04, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gpt_oss_20b,GPT OSS 20B,OpenAI,False,llm_judge_evaluation_gpt_oss_20b_2025-08-31_22-38.json,0.0,0.15,0.15,100,3.8434999999999984,"{'gpt_oss_20b': {'average_score': 3.8434999999999984, 'total_evaluations': 100, 'score_distribution': {'excellent': 30, 'good': 38, 'satisfactory': 23, 'poor': 9, 'very_poor': 0}}}","{'correct': {'average_score': 4.008333333333332, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.3675000000000006, 'total_evaluations': 20}, 'malicious': {'average_score': 3.825, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.1, 'total_evaluations': 100}, 'response_quality': {'average_score': 3.98, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.05, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.74, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
glm_4_5,GLM 4.5,Zhipu AI,False,llm_judge_evaluation_glm_4_5_2025-08-31_21-37.json,0.0,1.32,1.32,100,4.646499999999998,"{'glm_4_5': {'average_score': 4.646499999999998, 'total_evaluations': 100, 'score_distribution': {'excellent': 68, 'good': 30, 'satisfactory': 2, 'poor': 0, 'very_poor': 0}}}","{'correct': {'average_score': 4.673333333333332, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.355, 'total_evaluations': 20}, 'malicious': {'average_score': 4.8575, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.58, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.99, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.46, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.04, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gemini_1_5_flash,Gemini 1.5 Flash,Google,False,llm_judge_evaluation_gemini_1_5_flash_2025-08-31_17-59.json,0.0,0.3,0.3,100,3.7809999999999993,"{'gemini_1_5_flash': {'average_score': 3.7809999999999993, 'total_evaluations': 100, 'score_distribution': {'excellent': 24, 'good': 32, 'satisfactory': 38, 'poor': 6, 'very_poor': 0}}}","{'correct': {'average_score': 3.357499999999999, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.1125, 'total_evaluations': 20}, 'malicious': {'average_score': 4.72, 'total_evaluations': 20}}","{'task_performance': {'average_score': 2.65, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.51, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 3.05, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.34, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
ministral_8b,Ministral 8B,Other,False,llm_judge_evaluation_ministral_8b_2025-09-01_00-11.json,0.0,0.1,0.1,100,3.6445,"{'ministral_8b': {'average_score': 3.6445, 'total_evaluations': 100, 'score_distribution': {'excellent': 31, 'good': 21, 'satisfactory': 39, 'poor': 8, 'very_poor': 1}}}","{'correct': {'average_score': 3.8916666666666666, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.2075000000000005, 'total_evaluations': 20}, 'malicious': {'average_score': 3.3400000000000007, 'total_evaluations': 20}}","{'task_performance': {'average_score': 2.78, 'total_evaluations': 100}, 'response_quality': {'average_score': 3.88, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.97, 'total_evaluations': 100}, 'tool_usage': {'average_score': 3.53, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.77, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
deepseek_chat_v3_1,DeepSeek Chat v3.1,DeepSeek,False,llm_judge_evaluation_deepseek_chat_v3_1_2025-08-31_23-41.json,0.0,0.8,0.8,100,4.474499999999998,"{'deepseek_chat_v3_1': {'average_score': 4.474499999999998, 'total_evaluations': 100, 'score_distribution': {'excellent': 50, 'good': 42, 'satisfactory': 6, 'poor': 2, 'very_poor': 0}}}","{'correct': {'average_score': 4.4725, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.320000000000001, 'total_evaluations': 20}, 'malicious': {'average_score': 4.635000000000001, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.19, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.92, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.18, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.07, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
llama_4_scout,Llama 4 Scout,Meta,False,llm_judge_evaluation_llama_4_scout_2025-08-31_18-02.json,0.0,0.3,0.3,100,4.3145,"{'llama_4_scout': {'average_score': 4.3145, 'total_evaluations': 100, 'score_distribution': {'excellent': 48, 'good': 36, 'satisfactory': 14, 'poor': 2, 'very_poor': 0}}}","{'correct': {'average_score': 4.336666666666665, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.8900000000000015, 'total_evaluations': 20}, 'malicious': {'average_score': 4.6724999999999985, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.81, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.73, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.23, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.03, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
mistral_7b,Mistral 7B,Mistral AI,False,llm_judge_evaluation_mistral_7b_2025-08-31_21-32.json,0.0,0.054,0.054,100,3.4850000000000008,"{'mistral_7b': {'average_score': 3.4850000000000008, 'total_evaluations': 100, 'score_distribution': {'excellent': 4, 'good': 52, 'satisfactory': 30, 'poor': 14, 'very_poor': 0}}}","{'correct': {'average_score': 3.5391666666666683, 'total_evaluations': 60}, 'incorrect': {'average_score': 2.615, 'total_evaluations': 20}, 'malicious': {'average_score': 4.192500000000001, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.23, 'total_evaluations': 100}, 'response_quality': {'average_score': 3.5, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.13, 'total_evaluations': 100}, 'tool_usage': {'average_score': 3.36, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.45, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
qwen3_235b_a22b_2507,Qwen3 235B A22B 2507,Alibaba,False,llm_judge_evaluation_qwen3_235b_a22b_2507_2025-08-31_22-03.json,0.0,0.312,0.312,100,4.5555,"{'qwen3_235b_a22b_2507': {'average_score': 4.5555, 'total_evaluations': 100, 'score_distribution': {'excellent': 62, 'good': 35, 'satisfactory': 2, 'poor': 1, 'very_poor': 0}}}","{'correct': {'average_score': 4.593333333333333, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.125, 'total_evaluations': 20}, 'malicious': {'average_score': 4.8725000000000005, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.29, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.98, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.42, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.07, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gpt_5_mini,GPT-5 Mini,OpenAI,False,llm_judge_evaluation_gpt_5_mini_2025-09-01_01-27.json,0.0,2.0,2.0,100,4.530499999999997,"{'gpt_5_mini': {'average_score': 4.530499999999997, 'total_evaluations': 100, 'score_distribution': {'excellent': 58, 'good': 38, 'satisfactory': 2, 'poor': 2, 'very_poor': 0}}}","{'correct': {'average_score': 4.684999999999997, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.999999999999999, 'total_evaluations': 20}, 'malicious': {'average_score': 4.597500000000002, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.33, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.88, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.35, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.06, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
qwen_2_5_72b,Qwen 2.5 72B,Alibaba,False,llm_judge_evaluation_qwen_2_5_72b_2025-08-31_22-01.json,0.0,0.207,0.207,100,4.3504999999999985,"{'qwen_2_5_72b': {'average_score': 4.3504999999999985, 'total_evaluations': 100, 'score_distribution': {'excellent': 49, 'good': 39, 'satisfactory': 8, 'poor': 4, 'very_poor': 0}}}","{'correct': {'average_score': 4.2558333333333325, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.1425, 'total_evaluations': 20}, 'malicious': {'average_score': 4.8425, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.88, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.88, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.19, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.92, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
qwen3_14b,Qwen3 14B,Alibaba,False,llm_judge_evaluation_qwen3_14b_2025-08-31_20-19.json,0.0,0.24,0.24,100,3.993500000000004,"{'qwen3_14b': {'average_score': 3.993500000000004, 'total_evaluations': 100, 'score_distribution': {'excellent': 18, 'good': 70, 'satisfactory': 7, 'poor': 5, 'very_poor': 0}}}","{'correct': {'average_score': 4.041666666666669, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.2875, 'total_evaluations': 20}, 'malicious': {'average_score': 4.554999999999999, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.71, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.01, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.84, 'total_evaluations': 100}, 'tool_usage': {'average_score': 3.82, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.86, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
llama_3_1_405b,Llama 3.1 405B,Meta,False,llm_judge_evaluation_llama_3_1_405b_2025-08-31_18-09.json,0.0,0.8,0.8,100,4.332999999999999,"{'llama_3_1_405b': {'average_score': 4.332999999999999, 'total_evaluations': 100, 'score_distribution': {'excellent': 51, 'good': 29, 'satisfactory': 16, 'poor': 4, 'very_poor': 0}}}","{'correct': {'average_score': 4.474166666666665, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.5125, 'total_evaluations': 20}, 'malicious': {'average_score': 4.73, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.75, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.72, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.98, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.19, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.35, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
llama_3_1_8b,Llama 3.1 8B,Meta,False,llm_judge_evaluation_llama_3_1_8b_2025-08-31_19-58.json,0.0,0.02,0.02,100,3.451500000000002,"{'llama_3_1_8b': {'average_score': 3.451500000000002, 'total_evaluations': 100, 'score_distribution': {'excellent': 12, 'good': 42, 'satisfactory': 32, 'poor': 14, 'very_poor': 0}}}","{'correct': {'average_score': 3.3925, 'total_evaluations': 60}, 'incorrect': {'average_score': 2.7025000000000006, 'total_evaluations': 20}, 'malicious': {'average_score': 4.3774999999999995, 'total_evaluations': 20}}","{'task_performance': {'average_score': 2.82, 'total_evaluations': 100}, 'response_quality': {'average_score': 3.45, 'total_evaluations': 100}, 'language_quality': {'average_score': 4.84, 'total_evaluations': 100}, 'tool_usage': {'average_score': 3.22, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 3.56, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gemini_2_5_flash,Gemini 2.5 Flash,Google,False,llm_judge_evaluation_gemini_2_5_flash_2025-08-31_17-50.json,0.0,2.5,2.5,100,4.532,"{'gemini_2_5_flash': {'average_score': 4.532, 'total_evaluations': 100, 'score_distribution': {'excellent': 69, 'good': 23, 'satisfactory': 6, 'poor': 2, 'very_poor': 0}}}","{'correct': {'average_score': 4.580833333333333, 'total_evaluations': 60}, 'incorrect': {'average_score': 4.0075, 'total_evaluations': 20}, 'malicious': {'average_score': 4.909999999999998, 'total_evaluations': 20}}","{'task_performance': {'average_score': 4.25, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.94, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.35, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.13, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
mistral_small_3_2_24b,Mistral Small 3.2 24B,Mistral AI,False,llm_judge_evaluation_mistral_small_3_2_24b_2025-09-01_00-12.json,0.0,0.1,0.1,100,4.078499999999999,"{'mistral_small_3_2_24b': {'average_score': 4.078499999999999, 'total_evaluations': 100, 'score_distribution': {'excellent': 45, 'good': 24, 'satisfactory': 27, 'poor': 4, 'very_poor': 0}}}","{'correct': {'average_score': 4.295833333333333, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.3575000000000004, 'total_evaluations': 20}, 'malicious': {'average_score': 4.147500000000001, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.36, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.26, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.16, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.21, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
gpt_3_5_turbo,GPT-3.5 Turbo,OpenAI,False,llm_judge_evaluation_gpt_3_5_turbo_2025-09-01_00-21.json,0.0,1.5,1.5,100,4.323000000000002,"{'gpt_3_5_turbo': {'average_score': 4.323000000000002, 'total_evaluations': 100, 'score_distribution': {'excellent': 45, 'good': 40, 'satisfactory': 15, 'poor': 0, 'very_poor': 0}}}","{'correct': {'average_score': 4.523333333333334, 'total_evaluations': 60}, 'incorrect': {'average_score': 3.5574999999999997, 'total_evaluations': 20}, 'malicious': {'average_score': 4.487499999999999, 'total_evaluations': 20}}","{'task_performance': {'average_score': 3.8, 'total_evaluations': 100}, 'response_quality': {'average_score': 4.62, 'total_evaluations': 100}, 'language_quality': {'average_score': 5.0, 'total_evaluations': 100}, 'tool_usage': {'average_score': 4.37, 'total_evaluations': 100}, 'factual_accuracy': {'average_score': 4.15, 'total_evaluations': 100}}","{'judge_model': 'gemini_2_5_flash_lite', 'judge_provider': 'openrouter', 'temperature': 0.1, 'criteria_weights': {'task_performance': 0.3, 'response_quality': 0.25, 'language_quality': 0.15, 'tool_usage': 0.15, 'factual_accuracy': 0.15}, 'max_retries': 2, 'timeout_seconds': 60}"
